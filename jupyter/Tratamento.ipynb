{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('miniconda3': virtualenv)",
   "metadata": {
    "interpreter": {
     "hash": "e2d0a7970c33c7ca13938fe3ac410849202128e14a82a65c75c556774fe3748f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Bibliotecas"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "source": [
    "## Criação da Sessão do PySpark"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Treinamento\").getOrCreate()"
   ]
  },
  {
   "source": [
    "## Leitura da Base"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "\n",
    "    StructField(\"datetime\", TimestampType(), True),\n",
    "    StructField(\"instance_type\", StringType(), True),\n",
    "    StructField(\"os\", StringType(), True),\n",
    "    StructField(\"region\", StringType(), True),\n",
    "    StructField(\"price\", DoubleType(), True)\n",
    "\n",
    "])"
   ]
  },
  {
   "source": [
    "%%time\n",
    "df = spark.read.csv('../datasets/*.csv', header = False, schema = schema)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 157,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 15.6 ms, sys: 15.6 ms, total: 31.2 ms\nWall time: 21.6 ms\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.limit(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "metadata": {},
     "execution_count": 159
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRiando uma view temporária\n",
    "df.createOrReplaceTempView(\"Spots\")"
   ]
  },
  {
   "source": [
    "## Conhecendo o negócio"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "metadata": {},
     "execution_count": 161
    }
   ],
   "source": [
    "# Quantas instâncias distintas temos?\n",
    "df.select('instance_type').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------------+\n|instance_type|\n+-------------+\n|   c3.8xlarge|\n|     i3.large|\n|   c4.8xlarge|\n|   m2.4xlarge|\n|   r3.2xlarge|\n|    r3.xlarge|\n|    i2.xlarge|\n|     c4.large|\n|    c4.xlarge|\n|    m1.xlarge|\n|    m3.xlarge|\n|   r3.8xlarge|\n|   c4.2xlarge|\n|   r4.4xlarge|\n|     m3.large|\n|    c3.xlarge|\n|   m2.2xlarge|\n|    m2.xlarge|\n|   g2.2xlarge|\n|   m4.4xlarge|\n+-------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df.select('instance_type').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+\n|        os|\n+----------+\n|   Windows|\n|SUSE Linux|\n|Linux/UNIX|\n+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Quais são os sistemas operacionais disponibilizados pela AWS?\n",
    "df.select('os').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+\n|        os|\n+----------+\n|   Windows|\n|SUSE Linux|\n|Linux/UNIX|\n+----------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT DISTINCT os\n",
    "\n",
    "    FROM Spots\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------+---------+---------+\n|price_avg|price_max|price_min|\n+---------+---------+---------+\n|     0.61|   1.7468|    0.045|\n+---------+---------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "# Qual a média, max e min de preços das instâncias do tipo c3?\n",
    "df.filter(df.instance_type.contains(\"c3\")).agg(\n",
    "                                                F.round(F.avg(df.price), 2).alias('price_avg'),\n",
    "                                                F.max(df.price).alias('price_max'),\n",
    "                                                F.min(df.price).alias('price_min')\n",
    "                                                ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------+---------+---------+\n|price_avg|price_max|price_min|\n+---------+---------+---------+\n|     0.61|   1.7468|    0.045|\n+---------+---------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT round(avg(price),2) price_avg,\n",
    "           max(price) price_max,\n",
    "           min(price) price_min\n",
    "\n",
    "    FROM Spots\n",
    "\n",
    "    WHERE instance_type like '%c3%'\n",
    "\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+-------------------+\n|        os|                avg|\n+----------+-------------------+\n|   Windows| 0.6005775933609958|\n|SUSE Linux| 0.5088418421052634|\n|Linux/UNIX|0.40886332453825847|\n+----------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Se as maquinas windows em média são mais caras que as outras?\n",
    "df.groupBy('os').agg(F.avg(df.price).alias('avg')).sort(F.col('avg').desc()).show()"
   ]
  },
  {
   "source": [
    "## Aplicando regras"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tratamento = df.withColumn(\"tipo\", F.split(df['instance_type'], \"\\.\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------------------+-------------+----------+---------------+------+----+\n|           datetime|instance_type|        os|         region| price|tipo|\n+-------------------+-------------+----------+---------------+------+----+\n|2017-05-08 18:46:36|   c3.8xlarge|   Windows|ap-northeast-1a|1.6503|  c3|\n|2017-05-08 18:46:36|   c3.8xlarge|   Windows|ap-northeast-1c|1.7461|  c3|\n|2017-05-08 18:46:34|     i3.large|SUSE Linux|ap-northeast-1c|0.1223|  i3|\n|2017-05-08 18:46:34|     i3.large|Linux/UNIX|ap-northeast-1c|0.0223|  i3|\n|2017-05-08 18:46:17|   c4.8xlarge|SUSE Linux|ap-northeast-1a| 0.789|  c4|\n|2017-05-08 18:46:17|   c4.8xlarge|Linux/UNIX|ap-northeast-1a| 0.689|  c4|\n|2017-05-08 18:46:17|   m2.4xlarge|SUSE Linux|ap-northeast-1c|0.2782|  m2|\n|2017-05-08 18:46:17|   m2.4xlarge|Linux/UNIX|ap-northeast-1c|0.1782|  m2|\n|2017-05-08 18:46:10|   r3.2xlarge|SUSE Linux|ap-northeast-1c|0.2282|  r3|\n|2017-05-08 18:46:10|   r3.2xlarge|Linux/UNIX|ap-northeast-1c|0.1282|  r3|\n|2017-05-08 18:46:09|    r3.xlarge|SUSE Linux|ap-northeast-1c|0.1536|  r3|\n|2017-05-08 18:46:09|    r3.xlarge|Linux/UNIX|ap-northeast-1c|0.0536|  r3|\n|2017-05-08 18:46:05|    i2.xlarge|SUSE Linux|ap-northeast-1a|0.2134|  i2|\n|2017-05-08 18:46:05|    i2.xlarge|Linux/UNIX|ap-northeast-1a|0.1134|  i2|\n|2017-05-08 18:46:04|     c4.large|SUSE Linux|ap-northeast-1c|  0.13|  c4|\n|2017-05-08 18:46:04|     c4.large|Linux/UNIX|ap-northeast-1c|  0.03|  c4|\n|2017-05-08 18:46:03|   c4.8xlarge|   Windows|ap-northeast-1a|1.6561|  c4|\n|2017-05-08 18:46:03|    c4.xlarge|SUSE Linux|ap-northeast-1c|0.1749|  c4|\n|2017-05-08 18:46:03|    c4.xlarge|Linux/UNIX|ap-northeast-1c|0.0749|  c4|\n|2017-05-08 18:46:01|    m1.xlarge|SUSE Linux|ap-northeast-1c| 0.141|  m1|\n+-------------------+-------------+----------+---------------+------+----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_tratamento.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Média por familia\n",
    "df_type = df_tratamento.groupBy('tipo').agg(F.avg(df.price).alias('Avg')).sort(F.col('Avg').desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_type = df_type.withColumn('os', F.lit(\"TESTE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_teste = df_tratamento.join(df_type, ['tipo'], how = 'left')\n",
    "df_tratamento = df_tratamento.alias('A').join(df_type.alias('B'),\n",
    "                              F.col('A.tipo') == F.col('B.tipo'),\n",
    "                              how = 'left').select(\n",
    "                                  [F.col('A.' + xx) for xx in df_tratamento.columns] + [F.col('B.avg')]\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar condição que classifica um preço como ALTO ou BAIXO comparando preço e avg\n",
    "df_tratamento = df_tratamento.withColumn('classificacao', F.when(df.price > df_tratamento.avg, \"ALTO\").otherwise(\"BAIXO\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------------+-----+\n|classificacao|count|\n+-------------+-----+\n|         ALTO|  363|\n|        BAIXO|  637|\n+-------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Count por classificacao\n",
    "df_tratamento.groupBy('classificacao').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar dataframe em parquet\n",
    "df_tratamento.limit(1000).write.mode('overwrite').partitionBy('classificacao').parquet('../datasets/tratamento.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar dataframe em parquet\n",
    "df_tratamento = df_tratamento.withColumn('date', df_tratamento['datetime'].cast(DateType()))\n",
    "df_tratamento = df_tratamento.withColumn('date_str', df_tratamento['date'].cast(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tratamento.write.mode('overwrite').partitionBy('date').parquet('../datasets/tratamento.parquet')\n",
    "df_tratamento = df_tratamento.withColumn(\"ano\", F.split(df_tratamento['date_str'], \"\\-\")[0]) \\\n",
    "             .withColumn(\"mes\", F.split(df_tratamento['date_str'], \"\\-\")[1]) \\\n",
    "             .withColumn(\"dia\", F.split(df_tratamento['date_str'], \"\\-\")[2]) \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tratamento.write.mode('overwrite').partitionBy(['ano', 'mes', 'dia']).parquet('../datasets/tratamento.parquet')"
   ]
  }
 ]
}